---
title: Authenticity
---
AI companies never paid for the copyright to the content they were trained on. Though it sucks that writers, artists and publishing companies won't get paid, that is a first-order effect. When AI fails to pay writers and publishing companies, over time, those institutions will be unable to sustain the processes that produce the value that AI depends on. We need regulation to ensure that AI companies operate with an eye to their long-term viability and the viability of the rest of society.

As it is now, AI is like a fast-growing plant, perhaps a parasite, that has tapped into the nutrients of all our expertise-building institutions. It has sprouted up where the sunlight of attention, goodwill, and money usually lands and has spread a wide canopy, blocking out the light that usually falls on the leaves of these institutions. It has a shallow root system and isn't designed to sustainably generate expertise of its own. It also isn’t designed to transport money, goodwill, etc., down to the foundational plants it depends on. Instead, those life-giving nutrients go only to the AI companies, which grow larger still.

If this were on a small scale, AI might keep its host alive. But if it happens on large scale–people rely solely on AI to learn new skills, we stop buying books and depend instead on AI summaries, we rely on AI for therapy instead of therapists trained at institutions that move the practice forward–institutions will shrivel in the long term, and the contributions to progress that they nurtured will wane as well. 

Take the Stack Overflow use case. As a software engineer or data analyst, I use Stack Overflow as a resource to solve problems with my code. When I go there for an answer, I can say thank you or at least upvote an answer, and I can also contribute my own answers or improvements. It's designed to cultivate generosity. By saying thank you or upvoting an answer, I provide further motivation for my benefactors to continue helping, and by taking the opportunity to contribute myself, I do my part to maintain the community of giving. Stack Overflow isn't perfect, but it sustainably creates value and nurtures value creators.

AI provides specific code in response to a request. You don't know how AI got its answer, so you don't know who should get a thank you. If you see a way to improve the answer, or you come up with a new answer yourself, AI can't learn from you, since it takes an entire retraining of the model to learn new material. In the short term, AI outperforms Stack Overflow because you don't have to wade through irrelevant answers or wait for someone to respond to you. In the long term, though, the ecosystem of contribution and positive feedback is harmed. Seeing the impact of our work is a huge motivator for our generosity, but that impact is obfuscated by AI.

Similarly, when you buy a book, you pay the author. The author can sustain his livelihood, write more books, and other authors can do the same. If you use AI, a middleman gets your money, and that money doesn't spread back to the actual creators of the value. It's the same reason why piracy is a problem.

We need laws to ensure that value-producing institutions can sustain themselves. One way to do this is to ensure that AI pays back the institutions and people it relies on. This is the whole point of copyright law. Another way is to tax AI companies and redistribute their wealth back to value creators.

In the meantime, we programmers can keep the engines of goodwill turning by feeding answers taken from AI back into the Stack Overflow network. Other users can ask AI for resources rather than answers, and pony up with the knowledge that they aren't just getting theirs, but they are contributing to the long-term viability of society. We can recognize the debt we owe to creators of value–therapists, master software engineers, writers–and find ways to say thank you.