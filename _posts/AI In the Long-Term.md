---
title: AI in the Long-Term
layout: post
date: 2025-05-29
---

AI companies never paid for the copyright to the content they were trained on. Though it sucks that writers, artists and publishing companies won't get paid, that is a first-order effect. When AI fails to pay writers and publishing companies, over time, those institutions will be unable to sustain the processes that produce the value AI depends on. We need regulation to ensure that AI companies operate with an eye to their long-term viability and the viability of the rest of society.

Right now, AI is like a fast-growing plant, perhaps a parasite, that has tapped into the nutrients of all our expertise-building institutions. It has sprouted up where the sunlight of attention, goodwill, and money usually lands and has spread a wide canopy, blocking out the light that usually falls on the leaves of these institutions. However, the problem is not that AI is winning in competition with old institutions. It's that the new model doesn't have a nurturing feedback loop. It isn't designed to sustainably generate expertise of its own. It also isn’t designed to transport money, goodwill, etc., down to the foundational plants it depends on. Instead, those life-giving nutrients go only to the AI companies, which grow larger still.

If this were on a small scale, AI might keep its host alive. But if it happens on a large scale–people rely solely on AI to learn new skills, we stop buying books and depend instead on AI summaries, we rely on AI for therapy instead of therapists trained at institutions that move the practice forward–institutions will shrivel in the long term, and the contributions to progress that they nurtured will wane as well.

Take the Stack Overflow use case. As a software engineer or data analyst, I use Stack Overflow to troubleshoot code. When I browse, I can say thank you or at least upvote an answer, and I can also contribute my own answers or improvements. It's designed to cultivate generosity. By saying thank you or upvoting an answer, I provide further motivation for my benefactors to continue helping, and by taking the opportunity to contribute myself, I do my part to maintain the community of giving. Stack Overflow isn't perfect, but it sustainably creates value and nurtures value creators.

AI provides specific code in response to a request. You don't know how AI found its answer, so you don't know who should get a thank you. If you see a way to improve the answer or come up with a new answer yourself, AI can't learn from you, since it takes an entire retraining of the model to learn new material. In the short term, AI outperforms Stack Overflow because you don't have to wade through irrelevant answers or wait for someone to respond to you. In the long term, though, the ecosystem of contribution and positive feedback is [harmed](https://www.linkedin.com/pulse/fall-stack-overflow-how-ai-disrupted-developer-qa-giant-acharya-mgx9c/). Seeing the impact of our work is a huge motivator for our generosity, but that impact is obfuscated by AI.

Similarly, when you buy books, the authors get paid. They can sustain their livelihood and write more books. If you use AI, it gets your money, which doesn't return to the actual creators of the value. It's the same reason why piracy is a problem.

There is an ethical responsibility to ensure that value creators are rewarded when their work is used, but there is also a structural, purely mercenary impetus. Laws to ensure that value-producing institutions can sustain themselves, such as upholding copyright, solve both problems. Redistributing AI company wealth to value creators does too. These are models that potentially serve society at large, as we know it. AI companies can also solve the structural issue if they become self-sustaining–able to feed generated content back into their models to produce further improvements. So far, however, [research indicates](https://www.scientificamerican.com/article/ai-generated-data-can-poison-future-ai-models/) that when AI is trained on its own output, it collapses. This underscores the importance of partnering with human sources, rather than stealing from them. 

In the meantime, we programmers can keep the engines of goodwill turning by feeding answers taken from AI back into the Stack Overflow network. Other users can ask AI for books and articles rather than AI-generated answers, and pay for those sources with the knowledge that they are contributing to the long-term viability of society. We can recognize the debt we owe to creators of value–therapists, master software engineers, writers–and find ways to say thank you.
